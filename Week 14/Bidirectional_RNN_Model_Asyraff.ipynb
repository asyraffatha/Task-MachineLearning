{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAFFThwgkiUTUrW1oVlCSl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asyraffatha/Task-MachineLearning/blob/main/Week%2014/Bidirectional_RNN_Model_Asyraff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwL8XiJ_f808",
        "outputId": "6d6eab42-e508-4240-af42-2b910ad4a103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install torch torchvision scikit-learn\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7b_ZzAYhqE1",
        "outputId": "6a27581e-1dab-4a91-9a01-e4b0d2334596"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "file_path = \"/content/drive/MyDrive/Week 14/data.csv\"  # Adjust path as needed\n",
        "data = pd.read_csv(file_path, delimiter=';')"
      ],
      "metadata": {
        "id": "j3rkpCykhx6L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean column names and select numerical data\n",
        "data.columns = data.columns.str.strip()\n",
        "data = data.select_dtypes(include=[np.number]).dropna()"
      ],
      "metadata": {
        "id": "N7jOAvSVh6uC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)"
      ],
      "metadata": {
        "id": "yyfVwQCZh8M6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into features and target\n",
        "X = data_scaled[:, :-1]\n",
        "y = data_scaled[:, -1]"
      ],
      "metadata": {
        "id": "t8Lcbtbyh9nT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "55JrNqzZh_Pp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "1U0v-2rPiAcq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "j5iVfA40iB1K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Bidirectional RNN Model\n",
        "class BidirectionalRNNModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, pooling=\"max\"):\n",
        "        super(BidirectionalRNNModel, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.pooling = pooling\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)  # Multiply by 2 for bidirectional\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_out, _ = self.rnn(x)\n",
        "        if self.pooling == \"max\":\n",
        "            x = torch.max(rnn_out, dim=1)[0]\n",
        "        else:\n",
        "            x = torch.mean(rnn_out, dim=1)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "X7OR3d2kiD31"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment parameters\n",
        "hidden_sizes = [16, 32, 64]\n",
        "pooling_types = [\"max\", \"avg\"]\n",
        "epochs_list = [5, 50, 100, 250, 350]\n",
        "optimizers = [\"SGD\", \"RMSProp\", \"Adam\"]"
      ],
      "metadata": {
        "id": "u1dB2B-biFmx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_rnn(hidden_size, pooling, optimizer_name, epochs):\n",
        "    model = BidirectionalRNNModel(input_size=X_train.shape[1], hidden_size=hidden_size, output_size=1, pooling=pooling)\n",
        "    optimizer = {\"SGD\": optim.SGD, \"RMSProp\": optim.RMSprop, \"Adam\": optim.Adam}[optimizer_name](model.parameters(), lr=0.01)\n",
        "    criterion = nn.MSELoss()\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X.unsqueeze(1))  # Add sequence dimension\n",
        "            loss = criterion(outputs.squeeze(), batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "TxObnFpEiG9B"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main experiment\n",
        "results = []"
      ],
      "metadata": {
        "id": "sMvTjaOhiJBR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for hidden_size in hidden_sizes:\n",
        "    for pooling in pooling_types:\n",
        "        for optimizer_name in optimizers:\n",
        "            for epochs in epochs_list:\n",
        "                model = train_rnn(hidden_size, pooling, optimizer_name, epochs)\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    predictions = []\n",
        "                    for batch_X, _ in test_loader:\n",
        "                        pred = model(batch_X.unsqueeze(1))\n",
        "                        predictions.extend(pred.squeeze().tolist())\n",
        "                mse_loss = nn.MSELoss()(torch.tensor(predictions), y_test_tensor).item()\n",
        "                results.append({\n",
        "                    \"hidden_size\": hidden_size,\n",
        "                    \"pooling\": pooling,\n",
        "                    \"optimizer\": optimizer_name,\n",
        "                    \"epochs\": epochs,\n",
        "                    \"mse_loss\": mse_loss\n",
        "                })\n"
      ],
      "metadata": {
        "id": "QqTcqXzeiKbR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"bidir_rnn_results.csv\", index=False)\n",
        "print(\"Experiments completed. Results saved to 'bidir_rnn_results.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Xj86zXWiNSG",
        "outputId": "1ddfbe7f-c9cf-430f-f8ba-94636429542e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiments completed. Results saved to 'bidir_rnn_results.csv'.\n"
          ]
        }
      ]
    }
  ]
}